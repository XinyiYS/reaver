# params for generic actor-critic:
# ==========================================
ACAgent.model_fn = @build_fully_conv
ACAgent.policy_cls = @SC2MultiPolicy

ACAgent.optimizer = @tf.train.AdamOptimizer()
tf.train.AdamOptimizer.learning_rate = 0.0007

ACAgent.value_coef = 0.5
ACAgent.entropy_coef = 0.001

ACAgent.batch_sz = 32
ACAgent.traj_len = 40

ACAgent.discount = 0.99
ACAgent.gae_lambda = 0.0

ACAgent.clip_rewards = 0.0
ACAgent.clip_grads_norm = 10.0

ACAgent.normalize_returns = False
ACAgent.normalize_advantages = False

# params for A2C:
# ==========================================
# ...

# params for PPO:
# ==========================================
PPOAgent.gae_lambda = 0.95

PPOAgent.n_epochs = 3
PPOAgent.minibatch_sz = 128
PPOAgent.clip_ratio = 0.2
PPOAgent.clip_value = 0.0

PPOAgent.normalize_advantages = True

# params for HAI:
# ==========================================
HAIAgent.model_fn = @build_fully_conv
HAIAgent.policy_cls = @SC2MultiPolicy


# params for HRL_threshold
# ==========================================
HRL_threshold.BM = [5,5,5,5]
HRL_threshold.CMAG = [1000,10,1000,1000,1000,10,3500]



